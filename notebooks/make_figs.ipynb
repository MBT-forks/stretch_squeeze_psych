{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch and Squeeze Psychophysics Data Analysis and Figure Generation\n",
    "\n",
    "This notebook generates figure panels and performs statistical analyses for the psychophysics experiments in the Stretch and Squeeze paper. \n",
    "\n",
    "A de-identified version of all experimental data is being released for this project. The variable DEIDENTIFIED_DATA is \"True\" when using the de-identified dataset for the analysis. Setting it to \"False\" allows authors who have access to the raw source data to generate demographic tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEIDENTIFIED_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Setting fonttype to the meaning of life makes text editable in exported pdfs\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def get_df_from_xarray(data_paths, drop_columns=None):\n",
    "  start_pt_idx = 0\n",
    "  dfs = []\n",
    "  for data_path in data_paths: \n",
    "    assert os.path.isfile(data_path), f\"File {data_path} does not exist\"\n",
    "    ds = xr.open_dataset(data_path)\n",
    "    raw_df = ds.to_dataframe().reset_index()\n",
    "    df = raw_df[(raw_df['choice_slot'] == raw_df['i_choice']) | ((raw_df['i_choice'].isna()) & (raw_df['choice_slot'] == 0))]\n",
    "    df[\"participant\"] = start_pt_idx + df[\"participant\"]\n",
    "    start_pt_idx = start_pt_idx + df[\"participant\"].nunique()\n",
    "    dfs.append(df)\n",
    "\n",
    "  combined_df = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
    "\n",
    "  if drop_columns is not None:\n",
    "      combined_df = combined_df.drop(drop_columns, axis=1, errors='ignore')\n",
    "\n",
    "  # Sort dataframe such that trials for each participant appear in order\n",
    "  combined_df = combined_df.sort_values(by=['participant', 'obs'])\n",
    "\n",
    "  # Sort columns in a logical order\n",
    "  ordered_cols = ['participant', 'condition_idx', 'block', 'obs', 'trial_type', 'class', 'stimulus_image_url', 'stimulus_name', 'choice_name', 'i_correct_choice', 'i_choice', 'perf', 'reaction_time_msec', 'rel_timestamp_response', 'timestamp_start', 'monitor_width_px', 'monitor_height_px', 'stimulus_width_px', 'choice_width_px', 'stimulus_duration_msec', 'post_stimulus_delay_duration_msec', 'pre_choice_lockout_delay_duration_msec']\n",
    "  other_cols = [col for col in combined_df.columns if col not in ordered_cols]\n",
    "  combined_df = combined_df[ordered_cols + other_cols]\n",
    "\n",
    "  return combined_df\n",
    "\n",
    "\n",
    "# Function to calculate bootstrap confidence intervals\n",
    "def bootstrap_ci(data, num_bootstrap_samples=10000, confidence_level=0.95):\n",
    "    bootstrap_means = np.array([np.mean(np.random.choice(data, size=len(data), replace=True)) \n",
    "                                for _ in range(num_bootstrap_samples)])\n",
    "    return np.percentile(bootstrap_means, [(1 - confidence_level) / 2 * 100, (1 + confidence_level) / 2 * 100])\n",
    "\n",
    "\n",
    "def perform_chi_square(df, condition, control=0):\n",
    "    # Filter the dataframe for only the control and the specific condition\n",
    "    df_filtered = df[df['condition_idx'].isin([control, condition])]\n",
    "    \n",
    "    # Create a contingency table for the specific condition and control\n",
    "    contingency_table = pd.crosstab(df_filtered['condition_idx'], df_filtered['perf'])\n",
    "    \n",
    "    # Perform the Chi-square test\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    return chi2, p, dof, expected, contingency_table\n",
    "\n",
    "\n",
    "def chi_square_comparisons(df_trials_test, condition_idx_ordering, condition_labels, control_condition_idx=0):\n",
    "\n",
    "    control_group_name = condition_labels[condition_idx_ordering.index(control_condition_idx)]\n",
    "\n",
    "    # Perform chi-square tests for each condition compared to control\n",
    "    for label_idx, condition_idx in enumerate(condition_idx_ordering):\n",
    "        if condition_idx != control_condition_idx:\n",
    "            chi2, p, dof, expected, contingency_table = perform_chi_square(df_trials_test, condition_idx, control=control_condition_idx)\n",
    "            \n",
    "            print(f\"\\nComparing {condition_labels[label_idx]} to {control_group_name}:\")\n",
    "            print(f\"Chi-square value: {chi2:.4f}\")\n",
    "            print(f\"P-value: {p:.4f}\")\n",
    "            print(f\"Degrees of freedom: {dof}\")\n",
    "            \n",
    "            # Interpret the results\n",
    "            if p < 0.05:\n",
    "                print(f\"There is a significant difference in performance between {condition_labels[label_idx]} and {control_group_name}.\")\n",
    "            else:\n",
    "                print(f\"There is no significant difference in performance between {condition_labels[label_idx]} and {control_group_name}.\")\n",
    "            \n",
    "            # Display the contingency table\n",
    "            print(\"\\nContingency Table:\")\n",
    "            print(contingency_table)\n",
    "            \n",
    "            # Display expected frequencies\n",
    "            print(\"\\nExpected frequencies:\")\n",
    "            print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "\n",
    "def print_main_stats(df_trials, condition_idx_ordering, condition_labels, chance_level=0.25, test_blocks=[8,9]):\n",
    "  condition_accuracies = []\n",
    "  condition_cis = []\n",
    "\n",
    "  for cond in condition_idx_ordering:\n",
    "      cond_df = df_trials[(df_trials[\"condition_idx\"] == cond) & (df_trials[\"block\"].isin(test_blocks))]\n",
    "      mean_accuracy = cond_df['perf'].mean()\n",
    "      ci = bootstrap_ci(cond_df['perf'])\n",
    "      condition_accuracies.append(mean_accuracy)\n",
    "      condition_cis.append(ci)\n",
    "\n",
    "  # Create a DataFrame for plotting\n",
    "  condition_acc_data = pd.DataFrame({\n",
    "      'Condition': condition_labels,\n",
    "      'Accuracy': condition_accuracies,\n",
    "      'CI_lower': [ci[0] for ci in condition_cis],\n",
    "      'CI_upper': [ci[1] for ci in condition_cis]\n",
    "  })\n",
    "\n",
    "  # Calculate the error bars\n",
    "  condition_acc_data['yerr_lower'] = condition_acc_data['Accuracy'] - condition_acc_data['CI_lower']\n",
    "  condition_acc_data['yerr_upper'] = condition_acc_data['CI_upper'] - condition_acc_data['Accuracy']\n",
    "\n",
    "  print(\"Condition accuracies (mean with 95% CIs):\")\n",
    "  for condition, accuracy, ci in zip(condition_acc_data['Condition'], condition_acc_data['Accuracy'], condition_cis):\n",
    "      print(f\"{condition}: {accuracy:.2f} ({ci[0]:.2f}, {ci[1]:.2f})\")\n",
    "\n",
    "  # Calculate control accuracy (assumed to be the first condition)\n",
    "  control_accuracy = condition_acc_data['Accuracy'].iloc[0]\n",
    "\n",
    "  # Calculate and print percentage increase in margin above chance\n",
    "  print(\"\\nPercentage increase in margin above chance:\")\n",
    "  for condition, accuracy in zip(condition_acc_data['Condition'][1:], condition_acc_data['Accuracy'][1:]):  # Skip the first (control) condition\n",
    "      margin_control = control_accuracy - chance_level\n",
    "      margin_condition = accuracy - chance_level\n",
    "      \n",
    "      percentage_increase = ((margin_condition - margin_control) / margin_control) * 100\n",
    "\n",
    "      print(\"Condition acc:\", accuracy, \"| Control acc:\", control_accuracy)\n",
    "      print(\"Margin condition:\", margin_condition, \"| Margin control:\", margin_control)\n",
    "      print(f\"{condition}: {percentage_increase:.1f}%\")\n",
    "\n",
    "\n",
    "  # Calculate training time for each participant\n",
    "  df_trials_train = df_trials[~df_trials[\"block\"].isin(test_blocks)]\n",
    "  training_times = df_trials_train.groupby('participant')['rel_timestamp_response'].max().reset_index()\n",
    "  training_times = training_times.merge(df_trials_train[['participant', 'condition_idx']], on='participant', how='left')\n",
    "\n",
    "  # Function to calculate mean with bootstrap CI\n",
    "  def mean_with_ci(data, num_bootstrap_samples=10000, ci=0.95):\n",
    "      bootstrap_means = np.array([np.mean(np.random.choice(data, size=len(data), replace=True)) \n",
    "                                  for _ in range(num_bootstrap_samples)])\n",
    "      mean = np.mean(data)\n",
    "      ci_lower, ci_upper = np.percentile(bootstrap_means, [(1-ci)/2 * 100, (1+ci)/2 * 100])\n",
    "      return mean, ci_lower, ci_upper\n",
    "\n",
    "  # Calculate mean and CI for each condition\n",
    "  training_time_results = []\n",
    "  for c_idx, condition in enumerate(condition_idx_ordering):\n",
    "      if condition == 0 or condition:\n",
    "        condition_data = training_times[training_times['condition_idx'] == condition]['rel_timestamp_response']\n",
    "        mean, ci_lower, ci_upper = mean_with_ci(condition_data)\n",
    "        training_time_results.append({\n",
    "            'condition': condition_labels[c_idx],\n",
    "            'mean_training_time': round(mean/(1000*60), 4),\n",
    "            'ci_lower':  round(ci_lower/(1000*60), 4),\n",
    "            'ci_upper':  round(ci_upper/(1000*60), 4),\n",
    "        })\n",
    "\n",
    "  # Create a DataFrame with the results\n",
    "  training_time_results_df = pd.DataFrame(training_time_results)\n",
    "  print(\"Training times (minutes):\")\n",
    "  print(training_time_results_df)\n",
    "\n",
    "\n",
    "  # Calculate completion time for each participant\n",
    "  completion_times = df_trials.groupby('participant')['rel_timestamp_response'].max().reset_index()\n",
    "  completion_times = completion_times.merge(df_trials[['participant', 'condition_idx']], on='participant', how='left')\n",
    "\n",
    "  # Calculate mean and CI for each condition\n",
    "  completion_time_results = []\n",
    "  for c_idx, condition in enumerate(condition_idx_ordering):\n",
    "      if condition == 0 or condition:\n",
    "        condition_data = completion_times[completion_times['condition_idx'] == condition]['rel_timestamp_response']\n",
    "        mean, ci_lower, ci_upper = mean_with_ci(condition_data)\n",
    "        completion_time_results.append({\n",
    "            'condition': condition_labels[c_idx],\n",
    "            'mean_completion_time': round(mean/(1000*60), 4),\n",
    "            'ci_lower':  round(ci_lower/(1000*60), 4),\n",
    "            'ci_upper':  round(ci_upper/(1000*60), 4),\n",
    "        })\n",
    "\n",
    "  # Create a DataFrame with the results\n",
    "  completion_time_results_df = pd.DataFrame(completion_time_results)\n",
    "  print(\"Completion times (minutes):\")\n",
    "  print(completion_time_results_df)\n",
    "\n",
    "  return condition_acc_data, training_time_results_df, completion_time_results_df\n",
    "\n",
    "\n",
    "def assert_constant_counts(df):\n",
    "    # Print unique trial types for debugging\n",
    "    print(\"Unique trial types in the dataset:\", df['trial_type'].unique())\n",
    "    \n",
    "    # Group by trialset_id and get value counts for trial_type\n",
    "    counts = df.groupby(['experiment_id', 'trialset_id'])['trial_type'].value_counts().unstack(fill_value=0)\n",
    "    \n",
    "    # Get all unique trial types in the dataset\n",
    "    all_trial_types = ['calibration', 'repeat_stimulus']\n",
    "\n",
    "    for trial_type in all_trial_types:\n",
    "        if trial_type in counts.columns:\n",
    "            count_unique = counts[trial_type].nunique()\n",
    "            if count_unique != 1:\n",
    "                print(f\"\\nWarning: Count of {trial_type} is not constant across all trialset_ids\")\n",
    "                print(f\"Unique counts for {trial_type}: {counts[trial_type].unique()}\")\n",
    "            else:\n",
    "                print(f\"\\nCount of {trial_type} is constant ({counts[trial_type].iloc[0]}) across all trialset_ids\")\n",
    "        else:\n",
    "            print(f\"\\nWarning: Trial type '{trial_type}' is not present in counts DataFrame\")\n",
    "            print(\"This might indicate an issue with data processing\")\n",
    "\n",
    "    print(\"\\nAssertion check completed.\")\n",
    "\n",
    "\n",
    "def reassign_blocks(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Reassigns block values for specific participants in the dataframe based on observation numbers.\n",
    "    Only affects participants who have trials with 'shuffle' in their trial_type.\n",
    "    Includes verification of block sizes.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe containing columns 'participant', 'trial_type', 'obs', and 'block'\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with updated block values\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Find participants who have 'shuffle' in any of their trial_type values\n",
    "    shuffle_participants = df_copy[df_copy['trial_type'].str.contains('shuffle', na=False)]['participant'].unique()\n",
    "    \n",
    "    # Define the block structure\n",
    "    block_structure = {\n",
    "        0: 18,    # Block 0 has 18 trials\n",
    "        **{i: 19 for i in range(1, 8)},    # Blocks 1-7 have 19 trials each\n",
    "        **{i: 25 for i in range(8, 10)}    # Blocks 8-9 have 25 trials each\n",
    "    }\n",
    "\n",
    "    print(block_structure)\n",
    "    \n",
    "    # Calculate cumulative trial counts for block boundaries\n",
    "    cumulative_trials = [sum(block_structure[i] for i in range(k)) for k in range(len(block_structure) + 1)]\n",
    "    \n",
    "    # Function to assign block based on observation number\n",
    "    def get_block(obs):\n",
    "        for block_num, trial_boundary in enumerate(cumulative_trials[1:]):\n",
    "            if obs < trial_boundary:\n",
    "                return block_num\n",
    "        return len(block_structure) - 1  # Return last block number if beyond all boundaries\n",
    "    \n",
    "    # Process each participant who needs block reassignment\n",
    "    for participant in shuffle_participants:\n",
    "        # Get participant's data\n",
    "        mask = df_copy['participant'] == participant\n",
    "        participant_data = df_copy[mask].copy()\n",
    "        \n",
    "        # Sort by observation number\n",
    "        participant_data = participant_data.sort_values('obs')\n",
    "        \n",
    "        # Assign new block values based on observation position\n",
    "        df_copy.loc[mask, 'block'] = participant_data['obs'].apply(get_block)\n",
    "    \n",
    "    # Verify block sizes for each participant\n",
    "    print(\"\\nVerifying block sizes for each participant:\")\n",
    "    if verbose:\n",
    "        print(\"------------------------------------------\")\n",
    "    \n",
    "    all_correct = True\n",
    "    for participant in shuffle_participants:\n",
    "        participant_data = df_copy[df_copy['participant'] == participant]\n",
    "        \n",
    "        for block, expected_trials in block_structure.items():\n",
    "            block_trials = len(participant_data[participant_data['block'] == block])\n",
    "            \n",
    "            if block_trials != expected_trials:\n",
    "                print(f\"WARNING: Participant {participant} has {block_trials} trials in block {block} (expected {expected_trials})\")\n",
    "                all_correct = False\n",
    "            elif verbose:\n",
    "                print(f\"Participant {participant} has correct number of trials ({expected_trials}) in block {block}\")\n",
    "    \n",
    "    if all_correct:\n",
    "        print(\"\\nVERIFICATION PASSED: All participants have the correct number of trials in each block!\")\n",
    "    else:\n",
    "        print(\"\\nVERIFICATION FAILED: Some participants have incorrect numbers of trials in certain blocks.\")\n",
    "        \n",
    "    # Additional summary across all affected participants\n",
    "    if verbose:\n",
    "        print(\"\\nSummary across all participants with shuffled trials:\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "    for block, expected_trials in block_structure.items():\n",
    "        total_trials = sum(len(df_copy[(df_copy['participant'] == p) & (df_copy['block'] == block)]) \n",
    "                          for p in shuffle_participants)\n",
    "        num_participants = len(shuffle_participants)\n",
    "        if total_trials == expected_trials * num_participants:\n",
    "            if verbose:\n",
    "                print(f\"✓ Block {block}: All participants have exactly {expected_trials} trials\")\n",
    "        else:\n",
    "            print(f\"✗ Block {block}: Expected {expected_trials} trials per participant, \"\n",
    "                  f\"found {total_trials/num_participants:.1f} on average\")\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current working directory to the parent directory (which contains the \"notebooks\" directory among others)\n",
    "changed_dir = False\n",
    "if not changed_dir and os.path.exists(\"./make_figs.ipynb\"):\n",
    "  os.chdir(os.path.dirname(os.getcwd()))\n",
    "  changed_dir = True\n",
    "assert os.path.exists(\"./notebooks/make_figs.ipynb\"), \"Make sure your working directory starts in 'notebooks'\"\n",
    "\n",
    "os.makedirs(\"notebooks/fig_outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"stimulus_image_url_l\", \"stimulus_image_url_r\", \"class_l\", \"class_r\", \"mask_duration_msec\", \"mask_image_url\", \"choice_slot\", \"choice_image_urls\", \"keep_stimulus_on\", \"query_string\", \"platform\", \"bonus_usd_if_correct\"]\n",
    "if DEIDENTIFIED_DATA:\n",
    "  drop_columns.extend([\"assignment_id\", \"worker_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet 12-way object classification experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet12_dataset(data_path, RUN_TESTS=True, drop_columns=None):\n",
    "  # Load dataset and convert to a dataframe with 1 row per trial\n",
    "  ds = xr.open_dataset(data_path)\n",
    "\n",
    "  raw_df = ds.to_dataframe().reset_index()\n",
    "\n",
    "  # Filter rows where choice_slot equals i_choice\n",
    "  df = raw_df[raw_df['choice_slot'] == raw_df['i_choice']].copy()\n",
    "\n",
    "  # Sort dataframe such that trials for each participant appear in order\n",
    "  df = df.sort_values(by=['participant', 'obs'])\n",
    "\n",
    "  # Sort the columns in a logical order\n",
    "  ordered_cols = ['participant', 'condition_idx', 'block', 'obs', 'trial_type', 'class', 'stimulus_image_url', 'stimulus_name', 'choice_name', 'i_correct_choice', 'i_choice', 'perf', 'reaction_time_msec', 'rel_timestamp_response', 'timestamp_start', 'monitor_width_px', 'monitor_height_px', 'stimulus_width_px', 'choice_width_px', 'stimulus_duration_msec', 'post_stimulus_delay_duration_msec', 'pre_choice_lockout_delay_duration_msec']\n",
    "  other_cols = [col for col in df.columns if col not in ordered_cols]\n",
    "  df = df[ordered_cols + other_cols]\n",
    "\n",
    "  # Recover info about whether each image was from train, val, etc.\n",
    "  df[\"split\"] = df.apply(lambda row: row['stimulus_image_url'].split(\".s3.amazonaws.com/\")[1].split(\"/\")[0], axis=1)\n",
    "\n",
    "  if RUN_TESTS:\n",
    "    # Sanity check that will almost certainly fail if stimulus_name and choice_name are calculated incorrectly\n",
    "    for _, row in df.iterrows():\n",
    "      if row[\"i_choice\"] == row[\"i_correct_choice\"]:\n",
    "        assert(row[\"stimulus_name\"] == row[\"choice_name\"]), \"stim=\" + row[\"stimulus_name\"] + \", choice=\" + row[\"choice_name\"]\n",
    "      else:\n",
    "        assert(row[\"stimulus_name\"] != row[\"choice_name\"]), \"stim=\" + row[\"stimulus_name\"] + \", choice=\" + row[\"choice_name\"]\n",
    "\n",
    "  if drop_columns is not None:\n",
    "    df = df.drop(drop_columns, axis=1, errors='ignore')\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEIDENTIFIED_DATA and os.path.isfile(\"psych_data/df_main_6ani_6nonani_v1_2.csv\") and os.path.isfile(\"psych_data/df_main_6ani_6nonani_v1_4.csv\"):\n",
    "    print(\"Reading datasets from saved .csv\")\n",
    "    df_main_6ani_6nonani_v1_2 = pd.read_csv(\"psych_data/df_main_6ani_6nonani_v1_2.csv\")\n",
    "    df_main_6ani_6nonani_v1_4 = pd.read_csv(\"psych_data/df_main_6ani_6nonani_v1_4.csv\")\n",
    "else: # Load from raw .h5\n",
    "    print(\"Reading datasets from .h5 files\")\n",
    "\n",
    "    df_main_6ani_6nonani_v1_2 = load_imagenet12_dataset(\"./psych_data/6ani_6nonani_v1_2_combined_dataset.h5\", drop_columns=drop_columns)\n",
    "    df_main_6ani_6nonani_v1_2[\"experiment_id\"] = \"6ani_6nonani_v1_2\"\n",
    "\n",
    "    df_main_6ani_6nonani_v1_4 = load_imagenet12_dataset(\"./psych_data/6ani_6nonani_v1_4_combined_dataset.h5\", drop_columns=drop_columns)\n",
    "    df_main_6ani_6nonani_v1_4[\"experiment_id\"] = \"6ani_6nonani_v1_4\"\n",
    "\n",
    "    if DEIDENTIFIED_DATA:\n",
    "        print(\"Saving de-identified version of the dataset\")\n",
    "        df_main_6ani_6nonani_v1_2.to_csv(\"psych_data/df_main_6ani_6nonani_v1_2.csv\", index=False)\n",
    "        df_main_6ani_6nonani_v1_4.to_csv(\"psych_data/df_main_6ani_6nonani_v1_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def reconstruct_split_name(url):\n",
    "    \"\"\"\n",
    "    Extracts parts from the stimulus_image_url to create a new split name.\n",
    "    Expected format: \"base_folder-filename_part\"\n",
    "    Example Input: \"https://.../vanilla resnet50/unit [805]/Stretch in conv25/unit_[805]_Stretch in conv25_1.png\"\n",
    "    Example Output: \"vanilla_resnet50-Stretch_in_conv25\"\n",
    "    \"\"\"\n",
    "    if pd.isna(url) or not isinstance(url, str):\n",
    "        return None # Return None for missing or non-string URLs\n",
    "\n",
    "    try:\n",
    "        # Split the URL by '/'\n",
    "        parts = url.split('/')\n",
    "\n",
    "        # --- Part 1: Base-level folder name ---\n",
    "        # Assuming it's the first folder after the domain name (e.g., index 3)\n",
    "        if len(parts) > 3:\n",
    "            base_folder_raw = parts[3]\n",
    "            # Replace spaces with underscores\n",
    "            part1 = base_folder_raw.replace(' ', '_')\n",
    "        else:\n",
    "            # Handle unexpected URL structure\n",
    "            # print(f\"Warning: Could not extract base folder from URL: {url}\")\n",
    "            return None\n",
    "\n",
    "        # --- Part 2: Filename part ---\n",
    "        filename = parts[-1] # Get the last part (filename)\n",
    "\n",
    "        # Use regex to extract the part between unit_[<int>]_ and the final _<int>.png\n",
    "        # Pattern explanation:\n",
    "        # unit_\\[\\d+\\]_  : Matches \"unit_[\", one or more digits, \"]_\" literally\n",
    "        # (.*?)          : Captures any characters non-greedily (this is our target)\n",
    "        # _\\d+\\.png$     : Matches \"_\", one or more digits, \".png\" at the end of the string\n",
    "        match = re.search(r'unit_\\[\\d+\\]_(.*?)_\\d+\\.png$', filename)\n",
    "\n",
    "        if match:\n",
    "            filename_part_raw = match.group(1) # Get the captured group\n",
    "            # Replace spaces with underscores\n",
    "            part2 = filename_part_raw.replace(' ', '_')\n",
    "        else:\n",
    "            # Handle cases where the filename doesn't match the expected pattern\n",
    "            # print(f\"Warning: Could not extract filename part from: {filename} in URL: {url}\")\n",
    "            return None # Or potentially try alternative extraction logic if needed\n",
    "\n",
    "        # --- Combine the parts ---\n",
    "        return f\"{part1}-{part2}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors during processing\n",
    "        print(f\"Error processing URL: {url} - Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "#df_main_6ani_6nonani_v1_2['split_recon'] = df_main_6ani_6nonani_v1_2['stimulus_image_url'].apply(reconstruct_split_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_6ani_6nonani = df_main_6ani_6nonani_v1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_not_natural = df_main_6ani_6nonani['split'] != 'natural'\n",
    "\n",
    "# 2. Apply the function ONLY to the 'stimulus_image_url' of these rows\n",
    "#    This creates a Series containing the reconstructed names, indexed like the original non-natural rows\n",
    "reconstructed_names = df_main_6ani_6nonani.loc[condition_not_natural, 'stimulus_image_url'].apply(reconstruct_split_name)\n",
    "\n",
    "# 3. Initialize the 'split_recon' column with 'natural' as the default for ALL rows\n",
    "df_main_6ani_6nonani['split_recon'] = 'natural'\n",
    "\n",
    "# 4. Use .loc with the condition again to overwrite the 'split_recon' values\n",
    "#    ONLY for the non-natural rows, using the 'reconstructed_names' Series.\n",
    "#    Pandas automatically aligns the assignment based on the index.\n",
    "df_main_6ani_6nonani.loc[condition_not_natural, 'split_recon'] = reconstructed_names\n",
    "\n",
    "df_main_6ani_6nonani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Often used for nicer default plot styles\n",
    "\n",
    "split_col = \"split_recon\"\n",
    "\n",
    "# 1. Preprocessing: Handle NaNs in 'perf' column\n",
    "print(\"Original 'perf' value counts (including NaN):\")\n",
    "print(df_main_6ani_6nonani['perf'].value_counts(dropna=False))\n",
    "df_main_6ani_6nonani['perf_cleaned'] = df_main_6ani_6nonani['perf'].fillna(0)\n",
    "print(\"\\n'perf_cleaned' value counts (NaN replaced with 0):\")\n",
    "print(df_main_6ani_6nonani['perf_cleaned'].value_counts(dropna=False))\n",
    "\n",
    "# 2. Calculate Mean Performance per Split\n",
    "mean_perf = df_main_6ani_6nonani.groupby(split_col)['perf_cleaned'].mean()\n",
    "\n",
    "# 3. Calculate 95% Confidence Intervals per Split using bootstrap\n",
    "# Apply the bootstrap function to the 'perf_cleaned' data for each group\n",
    "ci_perf = df_main_6ani_6nonani.groupby(split_col)['perf_cleaned'].apply(\n",
    "    lambda x: bootstrap_ci(x, num_bootstrap_samples=10000, confidence_level=0.95)\n",
    ")\n",
    "\n",
    "# 4. Combine means and CIs into a summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'mean': mean_perf,\n",
    "    'ci': ci_perf\n",
    "})\n",
    "# Split the CI tuple into separate lower and upper bound columns\n",
    "summary_df[['ci_lower', 'ci_upper']] = pd.DataFrame(summary_df['ci'].tolist(), index=summary_df.index)\n",
    "summary_df = summary_df.drop(columns='ci') # Remove the original tuple column\n",
    "\n",
    "# 5. Sort the DataFrame according to requirements\n",
    "# Get unique split names\n",
    "split_names = summary_df.index.unique().tolist()\n",
    "\n",
    "# Sort alphabetically, but ensure 'natural' is first if it exists\n",
    "if 'natural' in split_names:\n",
    "    split_names.remove('natural')\n",
    "    sorted_splits = ['natural'] + sorted(split_names)\n",
    "else:\n",
    "    sorted_splits = sorted(split_names)\n",
    "\n",
    "# Reindex the summary DataFrame based on the desired order\n",
    "summary_df = summary_df.loc[sorted_splits]\n",
    "\n",
    "# Reset index to make 'split' a regular column for plotting\n",
    "summary_df = summary_df.reset_index()\n",
    "\n",
    "print(\"\\nSummary Statistics (Sorted):\")\n",
    "print(summary_df)\n",
    "\n",
    "# 6. Create the Bar Plot with Confidence Intervals\n",
    "\n",
    "# Calculate the error values for the plot (distance from the mean to the CI bounds)\n",
    "# yerr should be in the format [[lower_errors], [upper_errors]]\n",
    "lower_error = summary_df['mean'] - summary_df['ci_lower']\n",
    "upper_error = summary_df['ci_upper'] - summary_df['mean']\n",
    "error_bars = [lower_error, upper_error]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6)) # Adjust figure size as needed\n",
    "bars = plt.bar(summary_df[split_col], summary_df['mean'], yerr=error_bars, capsize=5, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Split Condition', fontsize=12)\n",
    "plt.ylabel('Mean Performance (Accuracy)', fontsize=12)\n",
    "plt.title('Mean Performance by Split with 95% Bootstrap CI (N=10,000)', fontsize=14)\n",
    "\n",
    "# Improve readability\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels if they overlap\n",
    "plt.ylim(0, 1.05) # Set y-axis limits appropriate for accuracy (0 to 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7) # Add horizontal grid lines\n",
    "\n",
    "# Add mean values on top of bars for clarity\n",
    "for bar, mean_val in zip(bars, summary_df['mean']):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.02, f'{mean_val:.3f}', va='bottom', ha='center', fontsize=9)\n",
    "\n",
    "# Ensure tight layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stretch_squeeze_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
